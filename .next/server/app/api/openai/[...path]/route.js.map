{"version":3,"file":"app/api/openai/[...path]/route.js","mappings":"oFAAAA,CAAAA,EAAAC,OAAA,CAAAC,QAAA,0CCAAF,CAAAA,EAAAC,OAAA,CAAAC,QAAA,ueEMA,IAAMC,EAAeC,CAAAA,EAAAA,EAAAA,CAAAA,IAEd,eAAeC,EAAcC,CAAgB,EAClD,IAAMC,EAAa,IAAIC,gBAEvB,IDX4BC,EAAcC,ECWtCC,EACFC,EAAiB,EACfT,CAAAA,EAAaU,OAAO,EACtBF,EACEL,EAAIQ,OAAO,CACRC,GAAG,CAAC,kBACHC,OACDC,WAAW,UAAW,IACtBD,QAAU,GAEfJ,EAAiB,YAEjBD,EAAYL,EAAIQ,OAAO,CAACC,GAAG,CAAC,kBAAoB,GAChDH,EAAiB,iBAGnB,IAAIH,EAAO,CAAC,EAAEH,EAAIY,OAAO,CAACC,QAAQ,CAAC,EAAEb,EAAIY,OAAO,CAACE,MAAM,CAAC,CAAC,CAACH,UAAU,CAClE,eACA,IAGEI,EACFlB,EAAamB,QAAQ,EAAInB,EAAakB,OAAO,EAAIE,EAAAA,EAAeA,CAE7DF,EAAQG,UAAU,CAAC,SACtBH,CAAAA,EAAU,CAAC,QAAQ,EAAEA,EAAQ,CAAC,EAG5BA,EAAQI,QAAQ,CAAC,MACnBJ,CAAAA,EAAUA,EAAQK,KAAK,CAAC,EAAG,GAAC,EAG9BC,QAAQC,GAAG,CAAC,WAAYnB,GACxBkB,QAAQC,GAAG,CAAC,aAAcP,GAE1B,IAAMQ,EAAYC,WAChB,KACEvB,EAAWwB,KAAK,EAClB,EACA,KAGF,GAAI5B,EAAaU,OAAO,CAAE,CACxB,GAAI,CAACV,EAAa6B,eAAe,CAC/B,OAAOC,EAAAA,EAAYA,CAACC,IAAI,CAAC,CACvBC,MAAO,GACPC,QAAS,8CACX,GD1DwB3B,EC4DLA,ED5DmBC,EC4DbP,EAAa6B,eAAe,CD1DzDvB,EAAOA,EAAKQ,UAAU,CAAC,MAAO,IC0D5BR,EDvDFA,GAAQ,CAAC,EAAEA,EAAK4B,QAAQ,CAAC,KAAO,IAAM,IAAI,YAAY,EAAE3B,EAAW,CAAC,CC0DpE,IAAM4B,EAAW,CAAC,EAAEjB,EAAQ,CAAC,EAAEZ,EAAK,CAAC,CAC/B8B,EAA4B,CAChCzB,QAAS,CACP,eAAgB,mBAChB,gBAAiB,WACjB,CAACF,EAAe,CAAED,EAClB,GAAIR,EAAaqC,WAAW,EAAI,CAC9B,sBAAuBrC,EAAaqC,WAAW,CAChD,EAEHC,OAAQnC,EAAImC,MAAM,CAClBC,KAAMpC,EAAIoC,IAAI,CAEdC,SAAU,SAEVC,OAAQ,OACRC,OAAQtC,EAAWsC,MAAM,EAI3B,GAAI1C,EAAa2C,YAAY,EAAIxC,EAAIoC,IAAI,CACvC,GAAI,CACF,IAAMK,EAAaC,CAAAA,EAAAA,EAAAA,EAAAA,EACjBC,EAAAA,EAAcA,CACd9C,EAAa2C,YAAY,EAErBI,EAAa,MAAM5C,EAAI6C,IAAI,EACjCZ,CAAAA,EAAaG,IAAI,CAAGQ,EAEpB,IAAME,EAAWC,KAAKC,KAAK,CAACJ,GAG5B,GAAIH,CAAgD,IAAhDA,CAAU,CAACK,GAAUG,OAAS,GAAG,CAACC,SAAS,CAC7C,OAAOvB,EAAAA,EAAYA,CAACC,IAAI,CACtB,CACEC,MAAO,GACPC,QAAS,CAAC,2BAA2B,EAAEgB,GAAUG,MAAM,MAAM,CAAC,EAEhE,CACEE,OAAQ,GACV,EAGN,CAAE,MAAOC,EAAG,CACV/B,QAAQQ,KAAK,CAAC,uBAAwBuB,EACxC,CAGF,GAAI,CACF,IAAMC,EAAM,MAAMC,MAAMtB,EAAUC,GAG9BsB,EAA2BF,EAAI7C,OAAO,CAACC,GAAG,CAAC,sBAG7CZ,CAAAA,EAAaqC,WAAW,EAAIrC,KAAAA,EAAaqC,WAAW,CAACxB,IAAI,GAE3DW,QAAQC,GAAG,CAAC,WAAYiC,GAExBlC,QAAQC,GAAG,CAAC,2BAIZ,IAAMkC,EAAa,IAAIC,QAAQJ,EAAI7C,OAAO,EAmB1C,OAlBAgD,EAAWE,MAAM,CAAC,oBAElBF,EAAWG,GAAG,CAAC,oBAAqB,MAK/B9D,EAAaqC,WAAW,EAAIrC,KAAAA,EAAaqC,WAAW,CAACxB,IAAI,IAC5D8C,EAAWE,MAAM,CAAC,uBAOpBF,EAAWE,MAAM,CAAC,oBAGX,IAAIE,SAASP,EAAIjB,IAAI,CAAE,CAC5Be,OAAQE,EAAIF,MAAM,CAClBU,WAAYR,EAAIQ,UAAU,CAC1BrD,QAASgD,CACX,EACF,QAAU,CACRM,aAAavC,EACf,CACF,CCjJA,IAAMwC,EAAc,IAAIC,IAAIC,OAAOC,MAAM,CAACC,EAAAA,EAAUA,GAcpD,eAAeC,EACbpE,CAAgB,CAChB,CAAEqE,OAAAA,CAAM,CAAkC,EAI1C,GAFAhD,QAAQC,GAAG,CAAC,yBAA0B+C,GAElCrE,YAAAA,EAAImC,MAAM,CACZ,OAAOR,EAAAA,EAAYA,CAACC,IAAI,CAAC,CAAEQ,KAAM,IAAK,EAAG,CAAEe,OAAQ,GAAI,GAGzD,IAAMmB,EAAUD,EAAOlE,IAAI,CAACoE,IAAI,CAAC,KAEjC,GAAI,CAACR,EAAYS,GAAG,CAACF,GAEnB,OADAjD,QAAQC,GAAG,CAAC,iCAAkCgD,GACvC3C,EAAAA,EAAYA,CAACC,IAAI,CACtB,CACEC,MAAO,GACP4C,IAAK,kCAAoCH,CAC3C,EACA,CACEnB,OAAQ,GACV,GAIJ,IAAMuB,EAAaC,CAAAA,EAAAA,EAAAA,CAAAA,EAAK3E,EAAK4E,EAAAA,EAAaA,CAACC,GAAG,EAC9C,GAAIH,EAAW7C,KAAK,CAClB,OAAOF,EAAAA,EAAYA,CAACC,IAAI,CAAC8C,EAAY,CACnCvB,OAAQ,GACV,GAGF,GAAI,CACF,IAAM2B,EAAW,MAAM/E,EAAcC,GAGrC,GAAIsE,IAAYH,EAAAA,EAAUA,CAACY,aAAa,EAAID,MAAAA,EAAS3B,MAAM,CAAU,KAhDtD6B,EAkDb,IAAMC,GAlDOD,EAiDI,MAAMF,EAASlD,IAAI,GA9CpCsD,CAFWpF,EAAAA,EAAAA,CAAAA,IAEJqF,WAAW,EACpBH,CAAAA,EAAeI,IAAI,CAAGJ,EAAeI,IAAI,CAACC,MAAM,CAC9C,GAAO,CAACC,EAAEC,EAAE,CAACrE,UAAU,CAAC,WAIrB8D,GA0CH,OAAOrD,EAAAA,EAAYA,CAACC,IAAI,CAACqD,EAAiB,CACxC9B,OAAQ2B,EAAS3B,MAAM,EAE3B,CAEA,OAAO2B,CACT,CAAE,MAAO1B,EAAG,CAEV,OADA/B,QAAQQ,KAAK,CAAC,YAAauB,GACpBzB,EAAAA,EAAYA,CAACC,IAAI,CAAC4D,CAAAA,EAAAA,EAAAA,CAAAA,EAAapC,GACxC,CACF,CAEO,IAAMqC,EAAMrB,EACNsB,EAAOtB,EAEPuB,EAAU,OACVC,EAAkB,CAC7B,OACA,OACA,OACA,OACA,OACA,OACA,OACA,OACA,OACA,OACA,OACA,OACA,OACA,OACA,OACA,OACA,OACD,CCxFDC,EAAA,IAAwBC,EAAAC,mBAAmB,EAC3CC,WAAA,CACAC,KAAcC,EAAAC,CAAS,CAAAC,SAAA,CACvBC,KAAA,8BACAxF,SAAA,wBACAyF,SAAA,QACAC,WAAA,gCACA,EACAC,iBAAA,uEACAC,iBAVA,aAWAC,SAAYC,CACZ,GAIA,CAAQC,oBAAAA,CAAA,CAAAC,6BAAAA,CAAA,CAAAC,YAAAA,CAAA,CAAAC,YAAAA,CAAA,CAAAC,wBAAAA,CAAA,EAAuGnB,EAC/GoB,EAAA,8BACA,SAAAC,IACA,MAAW,GAAAC,EAAAC,EAAA,EAAW,CACtBN,YAAAA,EACAD,6BAAAA,CACA,EACA,CC1BO,IAAAQ,EAAqBC,EAC5BC,EAAeC,EAAAC,CAAsB,CAAAC,IAAA,CAAM7B,4FCsBpC,SAASlB,EAAK3E,CAAgB,CAAE2H,CAA4B,EAIjE,GAAM,CAAEC,WAAAA,CAAU,CAAEC,OAAAA,CAAM,CAAE,CAAGC,SAdZC,CAAiB,EACpC,IAAMC,EAAQD,EAAUrH,IAAI,GAAGC,UAAU,CAAC,UAAW,IAAID,IAAI,GACvDuH,EAAW,CAACD,EAAM9G,UAAU,CAACgH,EAAAA,EAAkBA,EAErD,MAAO,CACLN,WAAYK,EAAW,GAAKD,EAAM5G,KAAK,CAAC8G,EAAAA,EAAkBA,CAACC,MAAM,EACjEN,OAAQI,EAAWD,EAAQ,EAC7B,CACF,EAGoBhI,EAAIQ,OAAO,CAACC,GAAG,CAAC,kBAAoB,IAKhD2H,EAAaC,IAAAA,IAAQ,CAACT,GAAc,IAAIlH,IAAI,GAE5Cb,EAAeC,CAAAA,EAAAA,EAAAA,CAAAA,IAOrB,GANAuB,QAAQC,GAAG,CAAC,gCAAiC,IAAIzB,EAAayI,KAAK,CAAC,EACpEjH,QAAQC,GAAG,CAAC,0BAA2BsG,GACvCvG,QAAQC,GAAG,CAAC,6BAA8B8G,GAC1C/G,QAAQC,GAAG,CAAC,aAAciH,SAjCbvI,CAAgB,EAC7B,IAAIwI,EAAKxI,EAAIwI,EAAE,EAAIxI,EAAIQ,OAAO,CAACC,GAAG,CAAC,aAC7BgI,EAAezI,EAAIQ,OAAO,CAACC,GAAG,CAAC,mBAMrC,MAJI,CAAC+H,GAAMC,GACTD,CAAAA,EAAKC,EAAaC,KAAK,CAAC,KAAKC,EAAE,CAAC,IAAM,IAGjCH,CACT,EAwBkCxI,IAChCqB,QAAQC,GAAG,CAAC,UAAW,IAAIsH,OAAOC,cAAc,IAE5ChJ,EAAaiJ,QAAQ,EAAI,CAACjJ,EAAayI,KAAK,CAAC9D,GAAG,CAAC4D,IAAe,CAACP,EACnE,MAAO,CACLhG,MAAO,GACP4C,IAAK,EAAoC,oBAAtB,mBACrB,EAGF,GAAI5E,EAAakJ,cAAc,EAAMlB,EACnC,MAAO,CACLhG,MAAO,GACP4C,IAAK,qDACP,EAIF,GAAKoD,EAmCHxG,QAAQC,GAAG,CAAC,+BAnCD,KAUP0H,EATJ,IAAMnJ,EAAeC,CAAAA,EAAAA,EAAAA,CAAAA,IAWrB,OAAQ6H,GACN,KAAK/C,EAAAA,EAAaA,CAACqE,SAAS,CAC1BD,EAAenJ,EAAaqJ,YAAY,CACxC,KACF,MAAKtE,EAAAA,EAAaA,CAACuE,MAAM,CACvBH,EAAenJ,EAAauJ,eAAe,CAC3C,KACF,MAAKxE,EAAAA,EAAaA,CAACC,GAAG,CACtB,QAEImE,EADEnJ,EAAaU,OAAO,CACPV,EAAawJ,WAAW,CAExBxJ,EAAagI,MAAM,CAIpCmB,GACF3H,QAAQC,GAAG,CAAC,6BACZtB,EAAIQ,OAAO,CAACmD,GAAG,CAAC,gBAAiB,CAAC,OAAO,EAAEqF,EAAa,CAAC,GAEzD3H,QAAQC,GAAG,CAAC,0CAEhB,CAIA,MAAO,CACLO,MAAO,EACT,CACF,iFCtDA,IAAMyH,EAAe,WACnB,IAAMC,EAAOC,QAAQC,GAAG,CAACC,IAAI,CAE7B,GAAI,CACF,IAAMpB,EAAQ,CAACiB,GAAMb,MAAM,MAAQ,EAAE,EAClCrD,MAAM,CAAC,GAAO,CAAC,CAACsE,GAChBC,GAAG,CAAC,GAAOvB,IAAAA,IAAQ,CAACsB,EAAEjJ,IAAI,KAC7B,OAAO,IAAIsD,IAAIsE,EACjB,CAAE,MAAOlF,EAAG,CACV,OAAO,IAAIY,GACb,CACF,IAEA,SAAS6F,EAAUC,CAAa,EAE9B,IAAMC,EAAUC,CADKF,GAAQ,IACApB,KAAK,CAAC,KAAKkB,GAAG,CAAC,GAAOD,EAAEjJ,IAAI,IACnDuJ,EAAcC,KAAKC,KAAK,CAACD,KAAKE,MAAM,GAAKL,EAAQ5B,MAAM,EACvDN,EAASkC,CAAO,CAACE,EAAY,CASnC,OARIpC,GACFxG,QAAQC,GAAG,CACT,CAAC,sBAAsB,EAAE2I,EAAc,EAAE,IAAI,EAC3CF,EAAQ5B,MAAM,CACf,WAAW,EAAEN,EAAO,CAAC,EAInBA,CACT,CAEO,IAAM/H,EAAsB,KACjC,GAAI,oBAAO0J,QACT,MAAMa,MACJ,4EAIJ,IAAMlF,EAAc,CAAC,CAACqE,QAAQC,GAAG,CAACa,YAAY,CAC1C9H,EAAegH,QAAQC,GAAG,CAACc,aAAa,EAAI,GAC5CC,EAAehB,QAAQC,GAAG,CAACgB,aAAa,EAAI,GAE5CtF,IACE3C,GAAcA,CAAAA,GAAgB,KAClCA,GAAgBG,EAAAA,EAAcA,CAAC0C,MAAM,CAAC,GAAOC,EAAEoF,IAAI,CAACxJ,UAAU,CAAC,UAC5D0I,GAAG,CAAC,GAAO,IAAMtE,EAAEoF,IAAI,EACvBnG,IAAI,CAAC,KACJiG,EAAatJ,UAAU,CAAC,UAAUsJ,CAAAA,EAAe,KAGvD,IAAMjK,EAAU,CAAC,CAACiJ,QAAQC,GAAG,CAACkB,SAAS,CACjCC,EAAW,CAAC,CAACpB,QAAQC,GAAG,CAACoB,cAAc,CACvCC,EAAc,CAAC,CAACtB,QAAQC,GAAG,CAACsB,iBAAiB,CAU7CC,EAAyB,CAC7BxB,QAAQC,GAAG,CAACwB,sBAAsB,EAAI,IACtCvC,KAAK,CAAC,KAER,MAAO,CACL3H,QAASyI,QAAQC,GAAG,CAACyB,QAAQ,CAC7BrD,OAAQgC,EAAUL,QAAQC,GAAG,CAAC0B,cAAc,EAC5CjJ,YAAasH,QAAQC,GAAG,CAAC2B,aAAa,CAEtC7K,QAAAA,EACAS,SAAUwI,QAAQC,GAAG,CAACkB,SAAS,CAC/BtB,YAAaQ,EAAUL,QAAQC,GAAG,CAAC4B,aAAa,EAChD3J,gBAAiB8H,QAAQC,GAAG,CAAC6B,iBAAiB,CAE9CV,SAAAA,EACA1B,aAAcW,EAAUL,QAAQC,GAAG,CAACoB,cAAc,EAClDU,UAAW/B,QAAQC,GAAG,CAAC+B,UAAU,CAEjCV,YAAAA,EACA1B,gBAAiBS,EAAUL,QAAQC,GAAG,CAACsB,iBAAiB,EACxDU,oBAAqBjC,QAAQC,GAAG,CAACiC,qBAAqB,CACtDC,aAAcnC,QAAQC,GAAG,CAACmC,aAAa,CAEvCC,MAAOrC,QAAQC,GAAG,CAACqC,MAAM,CAEzBhD,SAAUQ,EAAayC,IAAI,CAAG,EAC9BxC,KAAMC,QAAQC,GAAG,CAACC,IAAI,CACtBpB,MAAOgB,EAEP0C,SAAUxC,QAAQC,GAAG,CAACwC,SAAS,CAC/BC,SAAU,CAAC,CAAC1C,QAAQC,GAAG,CAAC0C,MAAM,CAE9BpD,eAAgB,CAAC,CAACS,QAAQC,GAAG,CAAC2C,iBAAiB,CAC/CjH,YAAAA,EACAkH,iBAAkB,CAAC7C,QAAQC,GAAG,CAAC6C,oBAAoB,CACnDC,gBAAiB,CAAC,CAAC/C,QAAQC,GAAG,CAAC+C,iBAAiB,CAChDhK,aAAAA,EACAgI,aAAAA,EACAQ,uBAAAA,CACF,CACF,4JCpIO,IAAM/J,EAAkB,yBAClBwL,EAAqB,4BAErBC,EAAkB,uDAEnBC,CAAAA,0GAAAA,GAAAA,CAAAA,EAAAA,CAAAA,CAAAA,YASAC,CAAAA,iEAAAA,GAAAA,CAAAA,EAAAA,CAAAA,CAAAA,YAMAC,CAAAA,qDAAAA,GAAAA,CAAAA,EAAAA,CAAAA,CAAAA,YAKAC,CAAAA,iDAAAA,GAAAA,CAAAA,EAAAA,CAAAA,CAAAA,YAKAC,CAAAA,iKAAAA,GAAAA,CAAAA,EAAAA,CAAAA,CAAAA,GAeL,IAAM7E,EAAqB,MAKrB8E,EAAc,6BAMfC,CAAAA,+EAAAA,GAAAA,CAAAA,EAAAA,CAAAA,CAAAA,YAOArI,CAAAA,yDAAAA,GAAAA,CAAAA,EAAAA,CAAAA,CAAAA,GAML,IAAMsI,EAAY,CACvBC,SAAU,cACVC,UAAW,cACXC,gBAAiB,4BACjBC,OAAQ,YACV,EAEanJ,EAAa,CACxBgJ,SAAU,sBACVI,UAAW,0BACXC,SAAU,iCACVzI,cAAe,WACjB,EA+EapC,EAAiB,IACzB8K,CAjCH,gBACA,qBACA,qBACA,QACA,aACA,YACA,iBACA,cACA,sBACA,SACA,oBACA,uBACA,yBACD,CAoBiB7D,GAAG,CAAC,GAAW,EAC7Bc,KAAAA,EACAxH,UAAW,GACXwK,SAAU,CACRnI,GAAI,SACJoI,aAAc,SACdC,aAAc,QAChB,CACF,OACGC,CA1BH,iBACA,wBACA,0BACA,oBACD,CAsBiBjE,GAAG,CAAC,GAAW,EAC7Bc,KAAAA,EACAxH,UAAW,GACXwK,SAAU,CACRnI,GAAI,SACJoI,aAAc,SACdC,aAAc,QAChB,CACF,OACGE,CA5BH,qBACA,aACA,aACA,2BACA,yBACA,0BACA,6BACD,CAqBoBlE,GAAG,CAAC,GAAW,EAChCc,KAAAA,EACAxH,UAAW,GACXwK,SAAU,CACRnI,GAAI,YACJoI,aAAc,YACdC,aAAc,WAChB,CACF,IACD,CAMYG,EAAiC,CAC5C,kCACA,2BACA,0BACA,kCACA,iCACA,8BACA,6BACA,4BACA,kCACD,8BCvNM,SAASvI,EAAaf,CAAQ,EACnC,IAAMuJ,EAAMvJ,QAIZ,CAHmB,UAAf,OAAOA,GACTA,CAAAA,EAAM1B,KAAKkL,SAAS,CAACxJ,EAAK,KAAM,OAE9BA,OAAAA,GACKuJ,EAAIE,QAAQ,GAEjBzJ,EAAIvD,UAAU,CAAC,WACVuD,EAEF,CAAC,UAAWA,EAAK,MAAM,CAACF,IAAI,CAAC,KACtC,gECVA,IAAM4J,EAAiB,GAAwB,EAC7C5I,GAAI6I,EACJT,aAAc,GACdC,aAAc,QAChB,GAEO,SAASlL,EACd2L,CAA2B,CAC3B7L,CAAoB,EAEpB,IAAMC,EASF,CAAC,EAmCL,OAhCA4L,EAAOC,OAAO,CAAC,IACb7L,CAAU,CAAC6C,EAAEoF,IAAI,CAAC,CAAG,CACnB,GAAGpF,CAAC,CACJiJ,YAAajJ,EAAEoF,IAAI,CAEvB,GAGAlI,EACGkG,KAAK,CAAC,KACNrD,MAAM,CAAC,GAAO,CAAC,CAACsE,GAAKA,EAAExB,MAAM,CAAG,GAChCmG,OAAO,CAAC,IACP,IAAMpL,EAAY,CAACoC,EAAEpE,UAAU,CAAC,KAG1B,CAACwJ,EAAM6D,EAAY,CAAGC,CAD1BlJ,EAAEpE,UAAU,CAAC,MAAQoE,EAAEpE,UAAU,CAAC,KAAOoE,EAAElE,KAAK,CAAC,GAAKkE,CAAAA,EACjBoD,KAAK,CAAC,IAGzCgC,CAAS,QAATA,EACFzG,OAAOC,MAAM,CAACzB,GAAY6L,OAAO,CAC/B,GAAYrL,EAAMC,SAAS,CAAGA,GAGhCT,CAAU,CAACiI,EAAK,CAAG,CACjBA,KAAAA,EACA6D,YAAaA,GAAe7D,EAC5BxH,UAAAA,EACAwK,SAAUjL,CAAU,CAACiI,EAAK,EAAEgD,UAAYS,EAAezD,EACzD,CAEJ,GAEKjI,CACT","sources":["webpack://_N_E/external commonjs \"node:async_hooks\"","webpack://_N_E/external commonjs \"node:buffer\"","webpack://_N_E/./app/azure.ts","webpack://_N_E/./app/api/common.ts","webpack://_N_E/./app/api/openai/[...path]/route.ts","webpack://_N_E/./app/api/openai/[...path]/route.ts?c4a0","webpack://_N_E/?8d9a","webpack://_N_E/./app/api/auth.ts","webpack://_N_E/./app/config/server.ts","webpack://_N_E/./app/constant.ts","webpack://_N_E/./app/utils/format.ts","webpack://_N_E/./app/utils/model.ts","webpack://_N_E/<anon>"],"sourcesContent":["module.exports = require(\"node:async_hooks\");","module.exports = require(\"node:buffer\");","export function makeAzurePath(path: string, apiVersion: string) {\n  // should omit /v1 prefix\n  path = path.replaceAll(\"v1/\", \"\");\n\n  // should add api-key to query string\n  path += `${path.includes(\"?\") ? \"&\" : \"?\"}api-version=${apiVersion}`;\n\n  return path;\n}\n","import { NextRequest, NextResponse } from \"next/server\";\nimport { getServerSideConfig } from \"../config/server\";\nimport { DEFAULT_MODELS, OPENAI_BASE_URL, GEMINI_BASE_URL } from \"../constant\";\nimport { collectModelTable } from \"../utils/model\";\nimport { makeAzurePath } from \"../azure\";\n\nconst serverConfig = getServerSideConfig();\n\nexport async function requestOpenai(req: NextRequest) {\n  const controller = new AbortController();\n\n  var authValue,\n    authHeaderName = \"\";\n  if (serverConfig.isAzure) {\n    authValue =\n      req.headers\n        .get(\"Authorization\")\n        ?.trim()\n        .replaceAll(\"Bearer \", \"\")\n        .trim() ?? \"\";\n\n    authHeaderName = \"api-key\";\n  } else {\n    authValue = req.headers.get(\"Authorization\") ?? \"\";\n    authHeaderName = \"Authorization\";\n  }\n\n  let path = `${req.nextUrl.pathname}${req.nextUrl.search}`.replaceAll(\n    \"/api/openai/\",\n    \"\",\n  );\n\n  let baseUrl =\n    serverConfig.azureUrl || serverConfig.baseUrl || OPENAI_BASE_URL;\n\n  if (!baseUrl.startsWith(\"http\")) {\n    baseUrl = `https://${baseUrl}`;\n  }\n\n  if (baseUrl.endsWith(\"/\")) {\n    baseUrl = baseUrl.slice(0, -1);\n  }\n\n  console.log(\"[Proxy] \", path);\n  console.log(\"[Base Url]\", baseUrl);\n\n  const timeoutId = setTimeout(\n    () => {\n      controller.abort();\n    },\n    10 * 60 * 1000,\n  );\n\n  if (serverConfig.isAzure) {\n    if (!serverConfig.azureApiVersion) {\n      return NextResponse.json({\n        error: true,\n        message: `missing AZURE_API_VERSION in server env vars`,\n      });\n    }\n    path = makeAzurePath(path, serverConfig.azureApiVersion);\n  }\n\n  const fetchUrl = `${baseUrl}/${path}`;\n  const fetchOptions: RequestInit = {\n    headers: {\n      \"Content-Type\": \"application/json\",\n      \"Cache-Control\": \"no-store\",\n      [authHeaderName]: authValue,\n      ...(serverConfig.openaiOrgId && {\n        \"OpenAI-Organization\": serverConfig.openaiOrgId,\n      }),\n    },\n    method: req.method,\n    body: req.body,\n    // to fix #2485: https://stackoverflow.com/questions/55920957/cloudflare-worker-typeerror-one-time-use-body\n    redirect: \"manual\",\n    // @ts-ignore\n    duplex: \"half\",\n    signal: controller.signal,\n  };\n\n  // #1815 try to refuse gpt4 request\n  if (serverConfig.customModels && req.body) {\n    try {\n      const modelTable = collectModelTable(\n        DEFAULT_MODELS,\n        serverConfig.customModels,\n      );\n      const clonedBody = await req.text();\n      fetchOptions.body = clonedBody;\n\n      const jsonBody = JSON.parse(clonedBody) as { model?: string };\n\n      // not undefined and is false\n      if (modelTable[jsonBody?.model ?? \"\"].available === false) {\n        return NextResponse.json(\n          {\n            error: true,\n            message: `you are not allowed to use ${jsonBody?.model} model`,\n          },\n          {\n            status: 403,\n          },\n        );\n      }\n    } catch (e) {\n      console.error(\"[OpenAI] gpt4 filter\", e);\n    }\n  }\n\n  try {\n    const res = await fetch(fetchUrl, fetchOptions);\n\n  // Extract the OpenAI-Organization header from the response\n  const openaiOrganizationHeader = res.headers.get(\"OpenAI-Organization\");\n\n  // Check if serverConfig.openaiOrgId is defined and not an empty string\n  if (serverConfig.openaiOrgId && serverConfig.openaiOrgId.trim() !== \"\") {\n    // If openaiOrganizationHeader is present, log it; otherwise, log that the header is not present\n    console.log(\"[Org ID]\", openaiOrganizationHeader);\n  } else {\n    console.log(\"[Org ID] is not set up.\");\n  }\n\n    // to prevent browser prompt for credentials\n    const newHeaders = new Headers(res.headers);\n    newHeaders.delete(\"www-authenticate\");\n    // to disable nginx buffering\n    newHeaders.set(\"X-Accel-Buffering\", \"no\");\n\n\n    // Conditionally delete the OpenAI-Organization header from the response if [Org ID] is undefined or empty (not setup in ENV)\n    // Also, this is to prevent the header from being sent to the client\n    if (!serverConfig.openaiOrgId || serverConfig.openaiOrgId.trim() === \"\") {\n      newHeaders.delete(\"OpenAI-Organization\");\n    }\n\n    // The latest version of the OpenAI API forced the content-encoding to be \"br\" in json response\n    // So if the streaming is disabled, we need to remove the content-encoding header\n    // Because Vercel uses gzip to compress the response, if we don't remove the content-encoding header\n    // The browser will try to decode the response with brotli and fail\n    newHeaders.delete(\"content-encoding\");\n\n\n    return new Response(res.body, {\n      status: res.status,\n      statusText: res.statusText,\n      headers: newHeaders,\n    });\n  } finally {\n    clearTimeout(timeoutId);\n  }\n}\n","import { type OpenAIListModelResponse } from \"@/app/client/platforms/openai\";\nimport { getServerSideConfig } from \"@/app/config/server\";\nimport { ModelProvider, OpenaiPath } from \"@/app/constant\";\nimport { prettyObject } from \"@/app/utils/format\";\nimport { NextRequest, NextResponse } from \"next/server\";\nimport { auth } from \"../../auth\";\nimport { requestOpenai } from \"../../common\";\n\nconst ALLOWD_PATH = new Set(Object.values(OpenaiPath));\n\nfunction getModels(remoteModelRes: OpenAIListModelResponse) {\n  const config = getServerSideConfig();\n\n  if (config.disableGPT4) {\n    remoteModelRes.data = remoteModelRes.data.filter(\n      (m) => !m.id.startsWith(\"gpt-4\"),\n    );\n  }\n\n  return remoteModelRes;\n}\n\nasync function handle(\n  req: NextRequest,\n  { params }: { params: { path: string[] } },\n) {\n  console.log(\"[OpenAI Route] params \", params);\n\n  if (req.method === \"OPTIONS\") {\n    return NextResponse.json({ body: \"OK\" }, { status: 200 });\n  }\n\n  const subpath = params.path.join(\"/\");\n\n  if (!ALLOWD_PATH.has(subpath)) {\n    console.log(\"[OpenAI Route] forbidden path \", subpath);\n    return NextResponse.json(\n      {\n        error: true,\n        msg: \"you are not allowed to request \" + subpath,\n      },\n      {\n        status: 403,\n      },\n    );\n  }\n\n  const authResult = auth(req, ModelProvider.GPT);\n  if (authResult.error) {\n    return NextResponse.json(authResult, {\n      status: 401,\n    });\n  }\n\n  try {\n    const response = await requestOpenai(req);\n\n    // list models\n    if (subpath === OpenaiPath.ListModelPath && response.status === 200) {\n      const resJson = (await response.json()) as OpenAIListModelResponse;\n      const availableModels = getModels(resJson);\n      return NextResponse.json(availableModels, {\n        status: response.status,\n      });\n    }\n\n    return response;\n  } catch (e) {\n    console.error(\"[OpenAI] \", e);\n    return NextResponse.json(prettyObject(e));\n  }\n}\n\nexport const GET = handle;\nexport const POST = handle;\n\nexport const runtime = \"edge\";\nexport const preferredRegion = [\n  \"arn1\",\n  \"bom1\",\n  \"cdg1\",\n  \"cle1\",\n  \"cpt1\",\n  \"dub1\",\n  \"fra1\",\n  \"gru1\",\n  \"hnd1\",\n  \"iad1\",\n  \"icn1\",\n  \"kix1\",\n  \"lhr1\",\n  \"pdx1\",\n  \"sfo1\",\n  \"sin1\",\n  \"syd1\",\n];\n","import { AppRouteRouteModule } from \"next/dist/server/future/route-modules/app-route/module.compiled\";\nimport { RouteKind } from \"next/dist/server/future/route-kind\";\nimport { patchFetch as _patchFetch } from \"next/dist/server/lib/patch-fetch\";\nimport * as userland from \"/Volumes/D/github/ChatGPT-Next-Web/app/api/openai/[...path]/route.ts\";\n// We inject the nextConfigOutput here so that we can use them in the route\n// module.\nconst nextConfigOutput = \"standalone\"\nconst routeModule = new AppRouteRouteModule({\n    definition: {\n        kind: RouteKind.APP_ROUTE,\n        page: \"/api/openai/[...path]/route\",\n        pathname: \"/api/openai/[...path]\",\n        filename: \"route\",\n        bundlePath: \"app/api/openai/[...path]/route\"\n    },\n    resolvedPagePath: \"/Volumes/D/github/ChatGPT-Next-Web/app/api/openai/[...path]/route.ts\",\n    nextConfigOutput,\n    userland\n});\n// Pull out the exports that we need to expose from the module. This should\n// be eliminated when we've moved the other routes to the new format. These\n// are used to hook into the route.\nconst { requestAsyncStorage, staticGenerationAsyncStorage, serverHooks, headerHooks, staticGenerationBailout } = routeModule;\nconst originalPathname = \"/api/openai/[...path]/route\";\nfunction patchFetch() {\n    return _patchFetch({\n        serverHooks,\n        staticGenerationAsyncStorage\n    });\n}\nexport { routeModule, requestAsyncStorage, staticGenerationAsyncStorage, serverHooks, headerHooks, staticGenerationBailout, originalPathname, patchFetch,  };\n\n//# sourceMappingURL=app-route.js.map","import { EdgeRouteModuleWrapper } from \"next/dist/server/web/edge-route-module-wrapper\";\n// Import the userland code.\nimport * as module from \"next-app-loader?name=app%2Fapi%2Fopenai%2F%5B...path%5D%2Froute&page=%2Fapi%2Fopenai%2F%5B...path%5D%2Froute&pagePath=private-next-app-dir%2Fapi%2Fopenai%2F%5B...path%5D%2Froute.ts&appDir=%2FVolumes%2FD%2Fgithub%2FChatGPT-Next-Web%2Fapp&appPaths=%2Fapi%2Fopenai%2F%5B...path%5D%2Froute&pageExtensions=tsx&pageExtensions=ts&pageExtensions=jsx&pageExtensions=js&basePath=&assetPrefix=&nextConfigOutput=standalone&preferredRegion=arn1&preferredRegion=bom1&preferredRegion=cdg1&preferredRegion=cle1&preferredRegion=cpt1&preferredRegion=dub1&preferredRegion=fra1&preferredRegion=gru1&preferredRegion=hnd1&preferredRegion=iad1&preferredRegion=icn1&preferredRegion=kix1&preferredRegion=lhr1&preferredRegion=pdx1&preferredRegion=sfo1&preferredRegion=sin1&preferredRegion=syd1&middlewareConfig=e30%3D!private-next-app-dir/api/openai/[...path]/route.ts?__next_edge_ssr_entry__\";\nexport const ComponentMod = module;\nexport default EdgeRouteModuleWrapper.wrap(module.routeModule);\n\n//# sourceMappingURL=edge-app-route.js.map","import { NextRequest } from \"next/server\";\nimport { getServerSideConfig } from \"../config/server\";\nimport md5 from \"spark-md5\";\nimport { ACCESS_CODE_PREFIX, ModelProvider } from \"../constant\";\n\nfunction getIP(req: NextRequest) {\n  let ip = req.ip ?? req.headers.get(\"x-real-ip\");\n  const forwardedFor = req.headers.get(\"x-forwarded-for\");\n\n  if (!ip && forwardedFor) {\n    ip = forwardedFor.split(\",\").at(0) ?? \"\";\n  }\n\n  return ip;\n}\n\nfunction parseApiKey(bearToken: string) {\n  const token = bearToken.trim().replaceAll(\"Bearer \", \"\").trim();\n  const isApiKey = !token.startsWith(ACCESS_CODE_PREFIX);\n\n  return {\n    accessCode: isApiKey ? \"\" : token.slice(ACCESS_CODE_PREFIX.length),\n    apiKey: isApiKey ? token : \"\",\n  };\n}\n\nexport function auth(req: NextRequest, modelProvider: ModelProvider) {\n  const authToken = req.headers.get(\"Authorization\") ?? \"\";\n\n  // check if it is openai api key or user token\n  const { accessCode, apiKey } = parseApiKey(authToken);\n\n  const hashedCode = md5.hash(accessCode ?? \"\").trim();\n\n  const serverConfig = getServerSideConfig();\n  console.log(\"[Auth] allowed hashed codes: \", [...serverConfig.codes]);\n  console.log(\"[Auth] got access code:\", accessCode);\n  console.log(\"[Auth] hashed access code:\", hashedCode);\n  console.log(\"[User IP] \", getIP(req));\n  console.log(\"[Time] \", new Date().toLocaleString());\n\n  if (serverConfig.needCode && !serverConfig.codes.has(hashedCode) && !apiKey) {\n    return {\n      error: true,\n      msg: !accessCode ? \"empty access code\" : \"wrong access code\",\n    };\n  }\n\n  if (serverConfig.hideUserApiKey && !!apiKey) {\n    return {\n      error: true,\n      msg: \"you are not allowed to access with your own api key\",\n    };\n  }\n\n  // if user does not provide an api key, inject system api key\n  if (!apiKey) {\n    const serverConfig = getServerSideConfig();\n\n    // const systemApiKey =\n    //   modelProvider === ModelProvider.GeminiPro\n    //     ? serverConfig.googleApiKey\n    //     : serverConfig.isAzure\n    //     ? serverConfig.azureApiKey\n    //     : serverConfig.apiKey;\n\n    let systemApiKey: string | undefined;\n\n    switch (modelProvider) {\n      case ModelProvider.GeminiPro:\n        systemApiKey = serverConfig.googleApiKey;\n        break;\n      case ModelProvider.Claude:\n        systemApiKey = serverConfig.anthropicApiKey;\n        break;\n      case ModelProvider.GPT:\n      default:\n        if (serverConfig.isAzure) {\n          systemApiKey = serverConfig.azureApiKey;\n        } else {\n          systemApiKey = serverConfig.apiKey;\n        }\n    }\n\n    if (systemApiKey) {\n      console.log(\"[Auth] use system api key\");\n      req.headers.set(\"Authorization\", `Bearer ${systemApiKey}`);\n    } else {\n      console.log(\"[Auth] admin did not provide an api key\");\n    }\n  } else {\n    console.log(\"[Auth] use user api key\");\n  }\n\n  return {\n    error: false,\n  };\n}\n","import md5 from \"spark-md5\";\nimport { DEFAULT_MODELS } from \"../constant\";\n\ndeclare global {\n  namespace NodeJS {\n    interface ProcessEnv {\n      PROXY_URL?: string; // docker only\n\n      OPENAI_API_KEY?: string;\n      CODE?: string;\n\n      BASE_URL?: string;\n      OPENAI_ORG_ID?: string; // openai only\n\n      VERCEL?: string;\n      BUILD_MODE?: \"standalone\" | \"export\";\n      BUILD_APP?: string; // is building desktop app\n\n      HIDE_USER_API_KEY?: string; // disable user's api key input\n      DISABLE_GPT4?: string; // allow user to use gpt-4 or not\n      ENABLE_BALANCE_QUERY?: string; // allow user to query balance or not\n      DISABLE_FAST_LINK?: string; // disallow parse settings from url or not\n      CUSTOM_MODELS?: string; // to control custom models\n      DEFAULT_MODEL?: string; // to cnntrol default model in every new chat window\n\n      // azure only\n      AZURE_URL?: string; // https://{azure-url}/openai/deployments/{deploy-name}\n      AZURE_API_KEY?: string;\n      AZURE_API_VERSION?: string;\n\n      // google only\n      GOOGLE_API_KEY?: string;\n      GOOGLE_URL?: string;\n\n      // google tag manager\n      GTM_ID?: string;\n\n      // custom template for preprocessing user input\n      DEFAULT_INPUT_TEMPLATE?: string;\n    }\n  }\n}\n\nconst ACCESS_CODES = (function getAccessCodes(): Set<string> {\n  const code = process.env.CODE;\n\n  try {\n    const codes = (code?.split(\",\") ?? [])\n      .filter((v) => !!v)\n      .map((v) => md5.hash(v.trim()));\n    return new Set(codes);\n  } catch (e) {\n    return new Set();\n  }\n})();\n\nfunction getApiKey(keys?: string) {\n  const apiKeyEnvVar = keys ?? \"\";\n  const apiKeys = apiKeyEnvVar.split(\",\").map((v) => v.trim());\n  const randomIndex = Math.floor(Math.random() * apiKeys.length);\n  const apiKey = apiKeys[randomIndex];\n  if (apiKey) {\n    console.log(\n      `[Server Config] using ${randomIndex + 1} of ${\n        apiKeys.length\n      } api key - ${apiKey}`,\n    );\n  }\n\n  return apiKey;\n}\n\nexport const getServerSideConfig = () => {\n  if (typeof process === \"undefined\") {\n    throw Error(\n      \"[Server Config] you are importing a nodejs-only module outside of nodejs\",\n    );\n  }\n\n  const disableGPT4 = !!process.env.DISABLE_GPT4;\n  let customModels = process.env.CUSTOM_MODELS ?? \"\";\n  let defaultModel = process.env.DEFAULT_MODEL ?? \"\";\n\n  if (disableGPT4) {\n    if (customModels) customModels += \",\";\n    customModels += DEFAULT_MODELS.filter((m) => m.name.startsWith(\"gpt-4\"))\n      .map((m) => \"-\" + m.name)\n      .join(\",\");\n    if (defaultModel.startsWith(\"gpt-4\")) defaultModel = \"\";\n  }\n\n  const isAzure = !!process.env.AZURE_URL;\n  const isGoogle = !!process.env.GOOGLE_API_KEY;\n  const isAnthropic = !!process.env.ANTHROPIC_API_KEY;\n\n  // const apiKeyEnvVar = process.env.OPENAI_API_KEY ?? \"\";\n  // const apiKeys = apiKeyEnvVar.split(\",\").map((v) => v.trim());\n  // const randomIndex = Math.floor(Math.random() * apiKeys.length);\n  // const apiKey = apiKeys[randomIndex];\n  // console.log(\n  //   `[Server Config] using ${randomIndex + 1} of ${apiKeys.length} api key`,\n  // );\n\n  const allowedWebDevEndpoints = (\n    process.env.WHITE_WEBDEV_ENDPOINTS ?? \"\"\n  ).split(\",\");\n\n  return {\n    baseUrl: process.env.BASE_URL,\n    apiKey: getApiKey(process.env.OPENAI_API_KEY),\n    openaiOrgId: process.env.OPENAI_ORG_ID,\n\n    isAzure,\n    azureUrl: process.env.AZURE_URL,\n    azureApiKey: getApiKey(process.env.AZURE_API_KEY),\n    azureApiVersion: process.env.AZURE_API_VERSION,\n\n    isGoogle,\n    googleApiKey: getApiKey(process.env.GOOGLE_API_KEY),\n    googleUrl: process.env.GOOGLE_URL,\n\n    isAnthropic,\n    anthropicApiKey: getApiKey(process.env.ANTHROPIC_API_KEY),\n    anthropicApiVersion: process.env.ANTHROPIC_API_VERSION,\n    anthropicUrl: process.env.ANTHROPIC_URL,\n\n    gtmId: process.env.GTM_ID,\n\n    needCode: ACCESS_CODES.size > 0,\n    code: process.env.CODE,\n    codes: ACCESS_CODES,\n\n    proxyUrl: process.env.PROXY_URL,\n    isVercel: !!process.env.VERCEL,\n\n    hideUserApiKey: !!process.env.HIDE_USER_API_KEY,\n    disableGPT4,\n    hideBalanceQuery: !process.env.ENABLE_BALANCE_QUERY,\n    disableFastLink: !!process.env.DISABLE_FAST_LINK,\n    customModels,\n    defaultModel,\n    allowedWebDevEndpoints,\n  };\n};\n","export const OWNER = \"Yidadaa\";\nexport const REPO = \"ChatGPT-Next-Web\";\nexport const REPO_URL = `https://github.com/${OWNER}/${REPO}`;\nexport const ISSUE_URL = `https://github.com/${OWNER}/${REPO}/issues`;\nexport const UPDATE_URL = `${REPO_URL}#keep-updated`;\nexport const RELEASE_URL = `${REPO_URL}/releases`;\nexport const FETCH_COMMIT_URL = `https://api.github.com/repos/${OWNER}/${REPO}/commits?per_page=1`;\nexport const FETCH_TAG_URL = `https://api.github.com/repos/${OWNER}/${REPO}/tags?per_page=1`;\nexport const RUNTIME_CONFIG_DOM = \"danger-runtime-config\";\n\nexport const DEFAULT_API_HOST = \"https://api.nextchat.dev\";\nexport const OPENAI_BASE_URL = \"https://api.openai.com\";\nexport const ANTHROPIC_BASE_URL = \"https://api.anthropic.com\";\n\nexport const GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/\";\n\nexport enum Path {\n  Home = \"/\",\n  Chat = \"/chat\",\n  Settings = \"/settings\",\n  NewChat = \"/new-chat\",\n  Masks = \"/masks\",\n  Auth = \"/auth\",\n}\n\nexport enum ApiPath {\n  Cors = \"\",\n  OpenAI = \"/api/openai\",\n  Anthropic = \"/api/anthropic\",\n}\n\nexport enum SlotID {\n  AppBody = \"app-body\",\n  CustomModel = \"custom-model\",\n}\n\nexport enum FileName {\n  Masks = \"masks.json\",\n  Prompts = \"prompts.json\",\n}\n\nexport enum StoreKey {\n  Chat = \"chat-next-web-store\",\n  Access = \"access-control\",\n  Config = \"app-config\",\n  Mask = \"mask-store\",\n  Prompt = \"prompt-store\",\n  Update = \"chat-update\",\n  Sync = \"sync\",\n}\n\nexport const DEFAULT_SIDEBAR_WIDTH = 300;\nexport const MAX_SIDEBAR_WIDTH = 500;\nexport const MIN_SIDEBAR_WIDTH = 230;\nexport const NARROW_SIDEBAR_WIDTH = 100;\n\nexport const ACCESS_CODE_PREFIX = \"nk-\";\n\nexport const LAST_INPUT_KEY = \"last-input\";\nexport const UNFINISHED_INPUT = (id: string) => \"unfinished-input-\" + id;\n\nexport const STORAGE_KEY = \"chatgpt-next-web\";\n\nexport const REQUEST_TIMEOUT_MS = 60000;\n\nexport const EXPORT_MESSAGE_CLASS_NAME = \"export-markdown\";\n\nexport enum ServiceProvider {\n  OpenAI = \"OpenAI\",\n  Azure = \"Azure\",\n  Google = \"Google\",\n  Anthropic = \"Anthropic\",\n}\n\nexport enum ModelProvider {\n  GPT = \"GPT\",\n  GeminiPro = \"GeminiPro\",\n  Claude = \"Claude\",\n}\n\nexport const Anthropic = {\n  ChatPath: \"v1/messages\",\n  ChatPath1: \"v1/complete\",\n  ExampleEndpoint: \"https://api.anthropic.com\",\n  Vision: \"2023-06-01\",\n};\n\nexport const OpenaiPath = {\n  ChatPath: \"v1/chat/completions\",\n  UsagePath: \"dashboard/billing/usage\",\n  SubsPath: \"dashboard/billing/subscription\",\n  ListModelPath: \"v1/models\",\n};\n\nexport const Azure = {\n  ExampleEndpoint: \"https://{resource-url}/openai/deployments/{deploy-id}\",\n};\n\nexport const Google = {\n  ExampleEndpoint: \"https://generativelanguage.googleapis.com/\",\n  ChatPath: (modelName: string) => `v1beta/models/${modelName}:generateContent`,\n};\n\nexport const DEFAULT_INPUT_TEMPLATE = `{{input}}`; // input / time / model / lang\n// export const DEFAULT_SYSTEM_TEMPLATE = `\n// You are ChatGPT, a large language model trained by {{ServiceProvider}}.\n// Knowledge cutoff: {{cutoff}}\n// Current model: {{model}}\n// Current time: {{time}}\n// Latex inline: $x^2$\n// Latex block: $$e=mc^2$$\n// `;\nexport const DEFAULT_SYSTEM_TEMPLATE = `\nYou are ChatGPT, a large language model trained by {{ServiceProvider}}.\nKnowledge cutoff: {{cutoff}}\nCurrent model: {{model}}\nCurrent time: {{time}}\nLatex inline: \\\\(x^2\\\\) \nLatex block: $$e=mc^2$$\n`;\n\nexport const SUMMARIZE_MODEL = \"gpt-3.5-turbo\";\nexport const GEMINI_SUMMARIZE_MODEL = \"gemini-pro\";\n\nexport const KnowledgeCutOffDate: Record<string, string> = {\n  default: \"2021-09\",\n  \"gpt-4-turbo\": \"2023-12\",\n  \"gpt-4-turbo-2024-04-09\": \"2023-12\",\n  \"gpt-4-turbo-preview\": \"2023-12\",\n  \"gpt-4o\": \"2023-10\",\n  \"gpt-4o-2024-05-13\": \"2023-10\",\n  \"gpt-4-vision-preview\": \"2023-04\",\n  // After improvements,\n  // it's now easier to add \"KnowledgeCutOffDate\" instead of stupid hardcoding it, as was done previously.\n  \"gemini-pro\": \"2023-12\",\n  \"gemini-pro-vision\": \"2023-12\",\n};\n\nconst openaiModels = [\n  \"gpt-3.5-turbo\",\n  \"gpt-3.5-turbo-1106\",\n  \"gpt-3.5-turbo-0125\",\n  \"gpt-4\",\n  \"gpt-4-0613\",\n  \"gpt-4-32k\",\n  \"gpt-4-32k-0613\",\n  \"gpt-4-turbo\",\n  \"gpt-4-turbo-preview\",\n  \"gpt-4o\",\n  \"gpt-4o-2024-05-13\",\n  \"gpt-4-vision-preview\",\n  \"gpt-4-turbo-2024-04-09\",\n];\n\nconst googleModels = [\n  \"gemini-1.0-pro\",\n  \"gemini-1.5-pro-latest\",\n  \"gemini-1.5-flash-latest\",\n  \"gemini-pro-vision\",\n];\n\nconst anthropicModels = [\n  \"claude-instant-1.2\",\n  \"claude-2.0\",\n  \"claude-2.1\",\n  \"claude-3-sonnet-20240229\",\n  \"claude-3-opus-20240229\",\n  \"claude-3-haiku-20240307\",\n  \"claude-3-5-sonnet-20240620\",\n];\n\nexport const DEFAULT_MODELS = [\n  ...openaiModels.map((name) => ({\n    name,\n    available: true,\n    provider: {\n      id: \"openai\",\n      providerName: \"OpenAI\",\n      providerType: \"openai\",\n    },\n  })),\n  ...googleModels.map((name) => ({\n    name,\n    available: true,\n    provider: {\n      id: \"google\",\n      providerName: \"Google\",\n      providerType: \"google\",\n    },\n  })),\n  ...anthropicModels.map((name) => ({\n    name,\n    available: true,\n    provider: {\n      id: \"anthropic\",\n      providerName: \"Anthropic\",\n      providerType: \"anthropic\",\n    },\n  })),\n] as const;\n\nexport const CHAT_PAGE_SIZE = 15;\nexport const MAX_RENDER_MSG_COUNT = 45;\n\n// some famous webdav endpoints\nexport const internalAllowedWebDavEndpoints = [\n  \"https://dav.jianguoyun.com/dav/\",\n  \"https://dav.dropdav.com/\",\n  \"https://dav.box.com/dav\",\n  \"https://nanao.teracloud.jp/dav/\",\n  \"https://bora.teracloud.jp/dav/\",\n  \"https://webdav.4shared.com/\",\n  \"https://dav.idrivesync.com\",\n  \"https://webdav.yandex.com\",\n  \"https://app.koofr.net/dav/Koofr\",\n];\n","export function prettyObject(msg: any) {\n  const obj = msg;\n  if (typeof msg !== \"string\") {\n    msg = JSON.stringify(msg, null, \"  \");\n  }\n  if (msg === \"{}\") {\n    return obj.toString();\n  }\n  if (msg.startsWith(\"```json\")) {\n    return msg;\n  }\n  return [\"```json\", msg, \"```\"].join(\"\\n\");\n}\n\nexport function* chunks(s: string, maxBytes = 1000 * 1000) {\n  const decoder = new TextDecoder(\"utf-8\");\n  let buf = new TextEncoder().encode(s);\n  while (buf.length) {\n    let i = buf.lastIndexOf(32, maxBytes + 1);\n    // If no space found, try forward search\n    if (i < 0) i = buf.indexOf(32, maxBytes);\n    // If there's no space at all, take all\n    if (i < 0) i = buf.length;\n    // This is a safe cut-off point; never half-way a multi-byte\n    yield decoder.decode(buf.slice(0, i));\n    buf = buf.slice(i + 1); // Skip space (if any)\n  }\n}\n","import { LLMModel } from \"../client/api\";\n\nconst customProvider = (modelName: string) => ({\n  id: modelName,\n  providerName: \"\",\n  providerType: \"custom\",\n});\n\nexport function collectModelTable(\n  models: readonly LLMModel[],\n  customModels: string,\n) {\n  const modelTable: Record<\n    string,\n    {\n      available: boolean;\n      name: string;\n      displayName: string;\n      provider?: LLMModel[\"provider\"]; // Marked as optional\n      isDefault?: boolean;\n    }\n  > = {};\n\n  // default models\n  models.forEach((m) => {\n    modelTable[m.name] = {\n      ...m,\n      displayName: m.name, // 'provider' is copied over if it exists\n    };\n  });\n\n  // server custom models\n  customModels\n    .split(\",\")\n    .filter((v) => !!v && v.length > 0)\n    .forEach((m) => {\n      const available = !m.startsWith(\"-\");\n      const nameConfig =\n        m.startsWith(\"+\") || m.startsWith(\"-\") ? m.slice(1) : m;\n      const [name, displayName] = nameConfig.split(\"=\");\n\n      // enable or disable all models\n      if (name === \"all\") {\n        Object.values(modelTable).forEach(\n          (model) => (model.available = available),\n        );\n      } else {\n        modelTable[name] = {\n          name,\n          displayName: displayName || name,\n          available,\n          provider: modelTable[name]?.provider ?? customProvider(name), // Use optional chaining\n        };\n      }\n    });\n\n  return modelTable;\n}\n\nexport function collectModelTableWithDefaultModel(\n  models: readonly LLMModel[],\n  customModels: string,\n  defaultModel: string,\n) {\n  let modelTable = collectModelTable(models, customModels);\n  if (defaultModel && defaultModel !== \"\") {\n    modelTable[defaultModel] = {\n      ...modelTable[defaultModel],\n      name: defaultModel,\n      available: true,\n      isDefault: true,\n    };\n  }\n  return modelTable;\n}\n\n/**\n * Generate full model table.\n */\nexport function collectModels(\n  models: readonly LLMModel[],\n  customModels: string,\n) {\n  const modelTable = collectModelTable(models, customModels);\n  const allModels = Object.values(modelTable);\n\n  return allModels;\n}\n\nexport function collectModelsWithDefaultModel(\n  models: readonly LLMModel[],\n  customModels: string,\n  defaultModel: string,\n) {\n  const modelTable = collectModelTableWithDefaultModel(\n    models,\n    customModels,\n    defaultModel,\n  );\n  const allModels = Object.values(modelTable);\n  return allModels;\n}\n"],"names":["module","exports","require","serverConfig","getServerSideConfig","requestOpenai","req","controller","AbortController","path","apiVersion","authValue","authHeaderName","isAzure","headers","get","trim","replaceAll","nextUrl","pathname","search","baseUrl","azureUrl","OPENAI_BASE_URL","startsWith","endsWith","slice","console","log","timeoutId","setTimeout","abort","azureApiVersion","NextResponse","json","error","message","includes","fetchUrl","fetchOptions","openaiOrgId","method","body","redirect","duplex","signal","customModels","modelTable","collectModelTable","DEFAULT_MODELS","clonedBody","text","jsonBody","JSON","parse","model","available","status","e","res","fetch","openaiOrganizationHeader","newHeaders","Headers","delete","set","Response","statusText","clearTimeout","ALLOWD_PATH","Set","Object","values","OpenaiPath","handle","params","subpath","join","has","msg","authResult","auth","ModelProvider","GPT","response","ListModelPath","remoteModelRes","availableModels","config","disableGPT4","data","filter","m","id","prettyObject","GET","POST","runtime","preferredRegion","routeModule","module_compiled","AppRouteRouteModule","definition","kind","route_kind","x","APP_ROUTE","page","filename","bundlePath","resolvedPagePath","nextConfigOutput","userland","route_namespaceObject","requestAsyncStorage","staticGenerationAsyncStorage","serverHooks","headerHooks","staticGenerationBailout","originalPathname","patchFetch","patch_fetch","XH","ComponentMod","route_next_edge_ssr_entry_namespaceObject","next_edge_app_route_loaderabsolutePagePath_private_next_app_dir_2Fapi_2Fopenai_2F_5B_path_5D_2Froute_ts_page_2Fapi_2Fopenai_2F_5B_path_5D_2Froute_appDirLoader_bmV4dC1hcHAtbG9hZGVyP25hbWU9YXBwJTJGYXBpJTJGb3BlbmFpJTJGJTVCLi4ucGF0aCU1RCUyRnJvdXRlJnBhZ2U9JTJGYXBpJTJGb3BlbmFpJTJGJTVCLi4ucGF0aCU1RCUyRnJvdXRlJnBhZ2VQYXRoPXByaXZhdGUtbmV4dC1hcHAtZGlyJTJGYXBpJTJGb3BlbmFpJTJGJTVCLi4ucGF0aCU1RCUyRnJvdXRlLnRzJmFwcERpcj0lMkZWb2x1bWVzJTJGRCUyRmdpdGh1YiUyRkNoYXRHUFQtTmV4dC1XZWIlMkZhcHAmYXBwUGF0aHM9JTJGYXBpJTJGb3BlbmFpJTJGJTVCLi4ucGF0aCU1RCUyRnJvdXRlJnBhZ2VFeHRlbnNpb25zPXRzeCZwYWdlRXh0ZW5zaW9ucz10cyZwYWdlRXh0ZW5zaW9ucz1qc3gmcGFnZUV4dGVuc2lvbnM9anMmYmFzZVBhdGg9JmFzc2V0UHJlZml4PSZuZXh0Q29uZmlnT3V0cHV0PXN0YW5kYWxvbmUmcHJlZmVycmVkUmVnaW9uPWFybjEmcHJlZmVycmVkUmVnaW9uPWJvbTEmcHJlZmVycmVkUmVnaW9uPWNkZzEmcHJlZmVycmVkUmVnaW9uPWNsZTEmcHJlZmVycmVkUmVnaW9uPWNwdDEmcHJlZmVycmVkUmVnaW9uPWR1YjEmcHJlZmVycmVkUmVnaW9uPWZyYTEmcHJlZmVycmVkUmVnaW9uPWdydTEmcHJlZmVycmVkUmVnaW9uPWhuZDEmcHJlZmVycmVkUmVnaW9uPWlhZDEmcHJlZmVycmVkUmVnaW9uPWljbjEmcHJlZmVycmVkUmVnaW9uPWtpeDEmcHJlZmVycmVkUmVnaW9uPWxocjEmcHJlZmVycmVkUmVnaW9uPXBkeDEmcHJlZmVycmVkUmVnaW9uPXNmbzEmcHJlZmVycmVkUmVnaW9uPXNpbjEmcHJlZmVycmVkUmVnaW9uPXN5ZDEmbWlkZGxld2FyZUNvbmZpZz1lMzAlM0Qh_nextConfigOutput_standalone_preferredRegion_arn1_preferredRegion_bom1_preferredRegion_cdg1_preferredRegion_cle1_preferredRegion_cpt1_preferredRegion_dub1_preferredRegion_fra1_preferredRegion_gru1_preferredRegion_hnd1_preferredRegion_iad1_preferredRegion_icn1_preferredRegion_kix1_preferredRegion_lhr1_preferredRegion_pdx1_preferredRegion_sfo1_preferredRegion_sin1_preferredRegion_syd1_middlewareConfig_e30_3D_","edge_route_module_wrapper","a","wrap","modelProvider","accessCode","apiKey","parseApiKey","bearToken","token","isApiKey","ACCESS_CODE_PREFIX","length","hashedCode","md5","codes","getIP","ip","forwardedFor","split","at","Date","toLocaleString","needCode","hideUserApiKey","systemApiKey","GeminiPro","googleApiKey","Claude","anthropicApiKey","azureApiKey","ACCESS_CODES","code","process","env","CODE","v","map","getApiKey","keys","apiKeys","apiKeyEnvVar","randomIndex","Math","floor","random","Error","DISABLE_GPT4","CUSTOM_MODELS","defaultModel","DEFAULT_MODEL","name","AZURE_URL","isGoogle","GOOGLE_API_KEY","isAnthropic","ANTHROPIC_API_KEY","allowedWebDevEndpoints","WHITE_WEBDEV_ENDPOINTS","BASE_URL","OPENAI_API_KEY","OPENAI_ORG_ID","AZURE_API_KEY","AZURE_API_VERSION","googleUrl","GOOGLE_URL","anthropicApiVersion","ANTHROPIC_API_VERSION","anthropicUrl","ANTHROPIC_URL","gtmId","GTM_ID","size","proxyUrl","PROXY_URL","isVercel","VERCEL","HIDE_USER_API_KEY","hideBalanceQuery","ENABLE_BALANCE_QUERY","disableFastLink","DISABLE_FAST_LINK","ANTHROPIC_BASE_URL","GEMINI_BASE_URL","Path","ApiPath","SlotID","FileName","StoreKey","STORAGE_KEY","ServiceProvider","Anthropic","ChatPath","ChatPath1","ExampleEndpoint","Vision","UsagePath","SubsPath","openaiModels","provider","providerName","providerType","googleModels","anthropicModels","internalAllowedWebDavEndpoints","obj","stringify","toString","customProvider","modelName","models","forEach","displayName","nameConfig"],"sourceRoot":""}